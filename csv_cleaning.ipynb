{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From ekidata.jp, 4 csv files containing data about train stations in Japan were obtained: station.csv, line.csv, company.csv and join.csv.\n",
    "\n",
    "Postcode data in Japan was obtained from post.japanpost.jp/zipcode/dl/utf-zip.html and is used to geocode the train stations.\n",
    "\n",
    "Opening the csv files and reading the data into pandas dataframes, we can see that some of the data is written in Japanese, such as the columns 'station_name' and 'address' in station.csv.  We need to convert this data to English for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the csv files\n",
    "station = pd.read_csv('station.csv')\n",
    "line =  pd.read_csv('line.csv')\n",
    "company = pd.read_csv('company.csv')\n",
    "join =  pd.read_csv('join.csv')\n",
    "postcode = pd.read_csv('postcode_jp.csv')\n",
    "\n",
    "# Print the output \n",
    "station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cutlet.py module,  we can convert the Japanese text to English.  We will use the following code to convert all the data that are Japanese to English from each csv file, and put the translated columns to the right of the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cutlet as ct\n",
    "\n",
    "# Load the csv files\n",
    "station = pd.read_csv('station.csv')\n",
    "line =  pd.read_csv('line.csv')\n",
    "company = pd.read_csv('company.csv')\n",
    "join =  pd.read_csv('join.csv')\n",
    "postcode = pd.read_csv('postcode_jp.csv')\n",
    "\n",
    "# Create a Cutlet object\n",
    "cutlet_obj = ct.Cutlet()\n",
    "\n",
    "# Define a function to translate Japanese text to English\n",
    "def translate_jp_to_en(text):\n",
    "    return cutlet_obj.romaji(text)\n",
    "\n",
    "# Apply the translation function to the japanese-lettered columns\n",
    "station['station_name_en'] = station['station_name'].apply(translate_jp_to_en)\n",
    "station['address_en'] = station['address'].apply(translate_jp_to_en)\n",
    "\n",
    "line['line_name_en'] = line['line_name'].apply(translate_jp_to_en)\n",
    "line['line_name_h_en'] = line['line_name_h'].apply(translate_jp_to_en)\n",
    "\n",
    "company['company_name_en'] = company['company_name'].apply(translate_jp_to_en)\n",
    "company['company_name_h_en'] = company['company_name_h'].apply(translate_jp_to_en)\n",
    "\n",
    "postcode['prefecture_en'] = postcode['prefecture'].apply(translate_jp_to_en)\n",
    "postcode['city_en'] = postcode['city'].apply(translate_jp_to_en)\n",
    "\n",
    "# Get the current column order\n",
    "cols_s = station.columns.tolist()\n",
    "cols_l = line.columns.tolist()\n",
    "cols_c = company.columns.tolist()\n",
    "cols_p = postcode.columns.tolist()\n",
    "\n",
    "# Move english-lettered columns to the right of japanese-lettered columns\n",
    "cols_s.insert(cols_s.index('station_name') + 1, cols_s.pop(cols_s.index('station_name_en')))\n",
    "cols_s.insert(cols_s.index('address') + 1, cols_s.pop(cols_s.index('address_en')))\n",
    "\n",
    "cols_l.insert(cols_l.index('line_name') + 1, cols_l.pop(cols_l.index('line_name_en')))\n",
    "cols_l.insert(cols_l.index('line_name_h') + 1, cols_l.pop(cols_l.index('line_name_h_en')))\n",
    "\n",
    "cols_c.insert(cols_c.index('company_name') + 1, cols_c.pop(cols_c.index('company_name_en')))\n",
    "cols_c.insert(cols_c.index('company_name_h') + 1, cols_c.pop(cols_c.index('company_name_h_en')))\n",
    "\n",
    "cols_p.insert(cols_p.index('prefecture') + 1, cols_p.pop(cols_p.index('prefecture_en')))\n",
    "cols_p.insert(cols_p.index('city') + 1, cols_p.pop(cols_p.index('city_en')))\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "station = station[cols_s]\n",
    "line = line[cols_l]\n",
    "company = company[cols_c]\n",
    "postcode = postcode[cols_p]\n",
    "\n",
    "# Print the output\n",
    "station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier for future data analysis, the translated 'city' and 'prefecture' columns from postcode.csv are merged into the station.csv file. \n",
    "\n",
    "This is done by inner join both the tables (left:station, right:postcode) based on the 'post' and 'postcode' column respectively. However, preliminary check on the 'post' data in the station.csv file shows that the value need cleaning like removing \"-\" and changing datatype to string. Some postcode also missed \"0 (zero)\" at the front due to csv not retaining 0 at the left of a number. This is also corrected. \n",
    "\n",
    "The edited tables (station, line, company) are then outputted as a new csv file to be used in data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '-' from the data in 'post' column\n",
    "station['post'] = station['post'].str.replace('-', '')\n",
    "\n",
    "# Convert the 'postcode' column to string type\n",
    "postcode['postcode'] = postcode['postcode'].astype(str)\n",
    "\n",
    "# Add a '0' to the left of the 'postcode' if it has less than 7 digits\n",
    "postcode['postcode'] = postcode['postcode'].apply(lambda x: '0' + x if len(x) < 7 else x)\n",
    "\n",
    "# Merge station.csv and postcode_jp.csv based on 'post' and 'postcode' columns\n",
    "station = pd.merge(station, postcode[['postcode', 'city_en', 'prefecture_en']], left_on='post', right_on='postcode', how='inner')\n",
    "\n",
    "# Rename the 'prefecture_en' to 'prefecture'\n",
    "station = station.rename(columns={'prefecture_en': 'prefecture'})\n",
    "\n",
    "\n",
    "# Output to csv file\n",
    "station.to_csv('station_updated.csv', index=False)\n",
    "company.to_csv('company_edited.csv', index=False)\n",
    "line.to_csv('line_edited.csv',  index=False)\n",
    "\n",
    "print(\"All processed data has been saved to CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All processed data has been saved to CSV files\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cutlet as ct\n",
    "\n",
    "# Load the csv files\n",
    "station = pd.read_csv('station.csv')\n",
    "line =  pd.read_csv('line.csv')\n",
    "company = pd.read_csv('company.csv')\n",
    "join =  pd.read_csv('join.csv')\n",
    "postcode = pd.read_csv('postcode_jp.csv')\n",
    "\n",
    "# Create a Cutlet object\n",
    "cutlet_obj = ct.Cutlet()\n",
    "\n",
    "# Define a function to translate Japanese text to English\n",
    "def translate_jp_to_en(text):\n",
    "    return cutlet_obj.romaji(text)\n",
    "\n",
    "# Apply the translation function to the japanese-lettered columns\n",
    "station['station_name_en'] = station['station_name'].apply(translate_jp_to_en)\n",
    "station['address_en'] = station['address'].apply(translate_jp_to_en)\n",
    "\n",
    "line['line_name_en'] = line['line_name'].apply(translate_jp_to_en)\n",
    "line['line_name_h_en'] = line['line_name_h'].apply(translate_jp_to_en)\n",
    "\n",
    "company['company_name_en'] = company['company_name'].apply(translate_jp_to_en)\n",
    "company['company_name_h_en'] = company['company_name_h'].apply(translate_jp_to_en)\n",
    "\n",
    "postcode['prefecture_en'] = postcode['prefecture'].apply(translate_jp_to_en)\n",
    "postcode['city_en'] = postcode['city'].apply(translate_jp_to_en)\n",
    "\n",
    "# Get the current column order\n",
    "cols_s = station.columns.tolist()\n",
    "cols_l = line.columns.tolist()\n",
    "cols_c = company.columns.tolist()\n",
    "cols_p = postcode.columns.tolist()\n",
    "\n",
    "\n",
    "# Move english-lettered columns to the right of japanese-lettered columns\n",
    "cols_s.insert(cols_s.index('station_name') + 1, cols_s.pop(cols_s.index('station_name_en')))\n",
    "cols_s.insert(cols_s.index('address') + 1, cols_s.pop(cols_s.index('address_en')))\n",
    "\n",
    "cols_l.insert(cols_l.index('line_name') + 1, cols_l.pop(cols_l.index('line_name_en')))\n",
    "cols_l.insert(cols_l.index('line_name_h') + 1, cols_l.pop(cols_l.index('line_name_h_en')))\n",
    "\n",
    "cols_c.insert(cols_c.index('company_name') + 1, cols_c.pop(cols_c.index('company_name_en')))\n",
    "cols_c.insert(cols_c.index('company_name_h') + 1, cols_c.pop(cols_c.index('company_name_h_en')))\n",
    "\n",
    "cols_p.insert(cols_p.index('prefecture') + 1, cols_p.pop(cols_p.index('prefecture_en')))\n",
    "cols_p.insert(cols_p.index('city') + 1, cols_p.pop(cols_p.index('city_en')))\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "station = station[cols_s]\n",
    "line = line[cols_l]\n",
    "company = company[cols_c]\n",
    "postcode = postcode[cols_p]\n",
    "\n",
    "# Remove '-' from the data in 'post' column\n",
    "station['post'] = station['post'].str.replace('-', '')\n",
    "\n",
    "# Convert the 'postcode' column to string type\n",
    "postcode['postcode'] = postcode['postcode'].astype(str)\n",
    "\n",
    "# Add a '0' to the left of the 'postcode' if it has less than 7 digits\n",
    "postcode['postcode'] = postcode['postcode'].apply(lambda x: '0' + x if len(x) < 7 else x)\n",
    "\n",
    "# Merge station.csv and postcode_jp.csv based on 'post' and 'postcode' columns\n",
    "station = pd.merge(station, postcode[['postcode', 'city_en', 'prefecture_en']], left_on='post', right_on='postcode', how='inner')\n",
    "\n",
    "# Rename the 'prefecture_en' to 'prefecture'\n",
    "station = station.rename(columns={'prefecture_en': 'prefecture'})\n",
    "\n",
    "\n",
    "\n",
    "# Print the output\n",
    "#station[station[['station_name_en', 'post', 'postcode', 'prefecture', 'city_en']].isnull().any(axis=1)] \n",
    "station.to_csv('station_updated_with_city.csv', index=False)\n",
    "\n",
    "print(\"All processed data has been saved to CSV files\")\n",
    "\n",
    "\n",
    "\n",
    "# Output to csv file\n",
    "\n",
    "#company.to_csv('company_edited.csv', index=False)\n",
    "#line.to_csv('line_edited.csv',  index=False)\n",
    "#print(\"All processed data has been saved to CSV files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing network visualization using NetworkX, Plotly\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load the data\n",
    "stations = pd.read_csv('station.csv')\n",
    "lines = pd.read_csv('line.csv')\n",
    "joins = pd.read_csv('join.csv')\n",
    "\n",
    "# Create a NetworkX graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes (stations) to the graph\n",
    "for index, row in stations.iterrows():\n",
    "    G.add_node(row['station_cd'], name=row['station_name'])\n",
    "\n",
    "# Add edges (lines) to the graph\n",
    "for index, row in joins.iterrows():\n",
    "    line_name = lines.loc[lines['line_cd'] == row['line_cd'], 'line_name'].iloc[0]\n",
    "    G.add_edge(row['station_cd1'], row['station_cd2'], line_cd=row['line_cd'], line_name=line_name)\n",
    "\n",
    "# Create a Plotly figure\n",
    "pos = nx.spring_layout(G)  # positions for all nodes\n",
    "node_trace = go.Scatter(x=[pos[node][0] for node in G.nodes()],\n",
    "                         y=[pos[node][1] for node in G.nodes()],\n",
    "                         mode='markers',\n",
    "                         hoverinfo='text',\n",
    "                         marker=dict(size=10, color='blue'),\n",
    "                         text=[G.nodes[node].get('name', node) for node in G.nodes()])\n",
    "edge_trace = go.Scatter(x=[], y=[], mode='lines', line=dict(color='gray', width=1), hoverinfo='text', hovertext=[])\n",
    "\n",
    "hovertext_list = list(edge_trace.hovertext)\n",
    "\n",
    "for edge in G.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_trace['x'] = list(edge_trace['x']) + [x0, x1, x0]\n",
    "    edge_trace['y'] = list(edge_trace['y']) + [y0, y1, y0]\n",
    "    hovertext_list.append(G.get_edge_data(edge[0], edge[1])['line_name'])\n",
    "\n",
    "edge_trace.hovertext = tuple(hovertext_list)\n",
    "\n",
    "fig = go.Figure(data=[node_trace, edge_trace],\n",
    "                layout=go.Layout(title='Station and Line Network',\n",
    "                                 width=800, height=600,\n",
    "                                 showlegend=False,\n",
    "                                 hovermode='closest',\n",
    "                                 margin=dict(b=20, l=5, r=5, t=40)))\n",
    "\n",
    "# Display the figure\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
